{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 12/22　CaT-GNN\n",
        "\n",
        "https://arxiv.org/pdf/2402.14708"
      ],
      "metadata": {
        "id": "1fklCXhNo1xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A. ランタイムを一度再起動してクリーンにしてください（UI: ランタイム → ランタイムを再起動）\n",
        "\n",
        "# B. 壊れた残骸を削除（警告に出ていた ~orch を消す）\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch\n",
        "\n",
        "# C. 既存の torch 関連と問題になりそうなパッケージを一旦アンインストール\n",
        "!pip uninstall -y torch torchvision torchaudio torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric fastai timm\n",
        "\n",
        "# D. pip の利用可能なバージョン一覧を確認（出力をここに貼ってください）\n",
        "!pip index versions torch\n",
        "!pip index versions torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghcDRGJau_CS",
        "outputId": "a729a5ed-a457-4c11-b4b3-d2689611087e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch_scatter 2.1.2+pt22cpu\n",
            "Uninstalling torch_scatter-2.1.2+pt22cpu:\n",
            "  Successfully uninstalled torch_scatter-2.1.2+pt22cpu\n",
            "Found existing installation: torch_sparse 0.6.18+pt22cpu\n",
            "Uninstalling torch_sparse-0.6.18+pt22cpu:\n",
            "  Successfully uninstalled torch_sparse-0.6.18+pt22cpu\n",
            "Found existing installation: torch_cluster 1.6.3+pt22cpu\n",
            "Uninstalling torch_cluster-1.6.3+pt22cpu:\n",
            "  Successfully uninstalled torch_cluster-1.6.3+pt22cpu\n",
            "Found existing installation: torch_spline_conv 1.2.2+pt22cpu\n",
            "Uninstalling torch_spline_conv-1.2.2+pt22cpu:\n",
            "  Successfully uninstalled torch_spline_conv-1.2.2+pt22cpu\n",
            "Found existing installation: torch-geometric 2.7.0\n",
            "Uninstalling torch-geometric-2.7.0:\n",
            "  Successfully uninstalled torch-geometric-2.7.0\n",
            "\u001b[33mWARNING: Skipping fastai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping timm as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: pip index is currently an experimental command. It may be removed/changed in a future release without prior warning.\u001b[0m\u001b[33m\n",
            "\u001b[0mtorch (2.9.1)\n",
            "Available versions: 2.9.1, 2.9.0, 2.8.0, 2.7.1, 2.7.0, 2.6.0, 2.5.1, 2.5.0, 2.4.1, 2.4.0, 2.3.1, 2.3.0, 2.2.2, 2.2.1, 2.2.0\n",
            "\u001b[33mWARNING: pip index is currently an experimental command. It may be removed/changed in a future release without prior warning.\u001b[0m\u001b[33m\n",
            "\u001b[0mtorchvision (0.24.1)\n",
            "Available versions: 0.24.1, 0.24.0, 0.23.0, 0.22.1, 0.22.0, 0.21.0, 0.20.1, 0.20.0, 0.19.1, 0.19.0, 0.18.1, 0.18.0, 0.17.2, 0.17.1, 0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOLZDFAu_djd",
        "outputId": "d49d66f2-c482-4f39-d39e-11ea1e1a24ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0+cpu\n",
            "Uninstalling torch-2.9.0+cpu:\n",
            "  Successfully uninstalled torch-2.9.0+cpu\n",
            "Found existing installation: torchvision 0.24.0+cpu\n",
            "Uninstalling torchvision-0.24.0+cpu:\n",
            "  Successfully uninstalled torchvision-0.24.0+cpu\n",
            "Found existing installation: torchaudio 2.9.0+cpu\n",
            "Uninstalling torchaudio-2.9.0+cpu:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cpu\n",
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-spline-conv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.6/495.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 423, in run\n",
            "    _, build_failures = build(\n",
            "                        ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 319, in build\n",
            "    wheel_file = _build_one(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 193, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 240, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "             ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1527, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.12/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1280, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1160, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 999, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 711, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 661, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 733, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 418, in _extract_from_extended_frame_gen\n",
            "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
            "                                                     ^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 355, in _walk_tb_with_full_positions\n",
            "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 369, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 423, in run\n",
            "    _, build_failures = build(\n",
            "                        ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 319, in build\n",
            "    wheel_file = _build_one(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 193, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 240, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "             ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
            "    with self:\n",
            "         ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 865, in __exit__\n",
            "    self._exit_buffer()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 823, in _exit_buffer\n",
            "    self._check_buffer()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 2060, in _check_buffer\n",
            "    self.file.write(text)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 43, in create_package_set_from_installed\n",
            "    package_set[name] = PackageDetails(dist.version, dependencies)\n",
            "                                       ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 175, in version\n",
            "    return parse_version(self._dist.version)\n",
            "                         ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/metadata/__init__.py\", line 467, in version\n",
            "    return self.metadata['Version']\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/metadata/__init__.py\", line 452, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/metadata/_adapters.py\", line 47, in __init__\n",
            "    self._headers = self._repair_headers()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/metadata/_adapters.py\", line 72, in _repair_headers\n",
            "    headers.append(('Description', self.get_payload()))\n",
            "                                   ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/email/message.py\", line 289, in get_payload\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# 1) ランタイムを再起動してクリーンな状態にする（UIで実行）\n",
        "# 壊れた残骸があれば削除\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch\n",
        "\n",
        "# 既存の関連パッケージを一旦削除\n",
        "!pip uninstall -y torch torchvision torchaudio torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "\n",
        "\n",
        "# 4) pip キャッシュをクリア（任意だが推奨）\n",
        "!pip cache purge\n",
        "\n",
        "# 5) CPU版の PyTorch / torchvision / torchaudio をインストール\n",
        "# CPU版を使う場合（確実）\n",
        "!pip install -q \"torch==2.9.1+cpu\" \"torchvision==0.24.1+cpu\" \"torchaudio==2.9.1\" --extra-index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "\n",
        "# 6) PyG の CPU 用ホイール（torch バージョンに合わせる）\n",
        "# torch のバージョン文字列が 2.9.1+cpu の場合\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.9.1+cpu.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.9.1+cpu.html\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-2.9.1+cpu.html\n",
        "!pip install -q torch-spline-conv -f https://data.pyg.org/whl/torch-2.9.1+cpu.html\n",
        "\n",
        "# torch-geometric 本体\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch_geometric\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"torch_geometric:\", torch_geometric.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "7wBMxnHWqBhE",
        "outputId": "8c28ea15-66b8-4e88-8c29-55a116bedb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3334978561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab / Python セルに貼って実行\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import roc_auc_score, f1_score, average_precision_score\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# ---------------------------\n",
        "# ユーティリティ\n",
        "# ---------------------------\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ---------------------------\n",
        "# サンプル合成データ（検証用）\n",
        "# 実データがある場合はここを置き換えてください\n",
        "# ---------------------------\n",
        "def make_synthetic_graph(num_nodes=1000, feat_dim=16, edge_prob=0.01):\n",
        "    x = torch.randn(num_nodes, feat_dim)\n",
        "    # timestamps: 0..T\n",
        "    t = torch.randint(0, 10, (num_nodes,)).float()\n",
        "    # random edges\n",
        "    rows = []\n",
        "    cols = []\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if i!=j and random.random() < edge_prob:\n",
        "                rows.append(i); cols.append(j)\n",
        "    edge_index = torch.tensor([rows, cols], dtype=torch.long)\n",
        "    # labels: small fraction fraud\n",
        "    y = (torch.rand(num_nodes) < 0.05).long()\n",
        "    return Data(x=x, edge_index=edge_index, y=y, t=t)\n",
        "\n",
        "data = make_synthetic_graph()\n",
        "data = data.to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# CT-GAT ブロック（Temporal GAT）\n",
        "# - GATConv をベースに、時間差を簡易的に組み込む\n",
        "# - attention weights を取得して重要度スコアに使う\n",
        "# ---------------------------\n",
        "class CTGATLayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, heads=4, concat=True, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.gat = GATConv(in_dim, out_dim // heads, heads=heads, concat=concat, dropout=dropout)\n",
        "        # 時刻埋め込み（簡易）\n",
        "        self.time_proj = nn.Linear(1, in_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index, t):\n",
        "        # t: [N] -> embed scalar time and add to features\n",
        "        t_emb = self.time_proj(t.view(-1,1))\n",
        "        x_in = x + t_emb\n",
        "        # GATConv で attention weights を得る（PyG の return_attention_weights）\n",
        "        out = self.gat(x_in, edge_index)\n",
        "        return self.dropout(out)\n",
        "\n",
        "    # attention weights を得るための補助（PyG の内部APIを使う）\n",
        "    def get_attention(self, x, edge_index):\n",
        "        # GATConv の attention を得るには forward with return_attention_weights\n",
        "        # PyG >= 2.0 の API を想定\n",
        "        _, (edge_index_out, attn) = self.gat(x, edge_index, return_attention_weights=True)\n",
        "        # attn: [num_edges, heads]\n",
        "        # aggregate per target node: mean attention from incoming edges per head\n",
        "        # compute importance per node by averaging attention across heads and incoming edges\n",
        "        num_nodes = x.size(0)\n",
        "        heads = attn.size(1)\n",
        "        # sum attention per target node\n",
        "        tgt = edge_index_out[1]\n",
        "        agg = torch.zeros(num_nodes, heads, device=x.device)\n",
        "        counts = torch.zeros(num_nodes, 1, device=x.device)\n",
        "        agg = agg.index_add(0, tgt, attn)\n",
        "        counts = counts.index_add(0, tgt, torch.ones_like(tgt, dtype=torch.float).view(-1,1))\n",
        "        counts[counts==0] = 1.0\n",
        "        agg = agg / counts\n",
        "        # importance scalar per node: mean over heads\n",
        "        importance = agg.mean(dim=1)  # [N]\n",
        "        return importance.detach()\n",
        "\n",
        "# ---------------------------\n",
        "# Causal-Inspector と Causal-Intervener を含む CaT-GNN モデル\n",
        "# ---------------------------\n",
        "class CaT_GNN(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim=128, heads=4, n_layers=2, env_ratio=0.3, mix_k=3, mix_mode='learn'):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(CTGATLayer(in_dim, hid_dim, heads=heads))\n",
        "        for _ in range(n_layers-1):\n",
        "            self.layers.append(CTGATLayer(hid_dim, hid_dim, heads=heads))\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hid_dim, hid_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hid_dim//2, 1)\n",
        "        )\n",
        "        self.env_ratio = env_ratio  # re: 環境ノード比率\n",
        "        self.mix_k = mix_k          # k: mixup に使う因果ノード数\n",
        "        self.mix_mode = mix_mode    # 'learn' or 'importance'\n",
        "        # mixup weight layer (if learnable)\n",
        "        if mix_mode == 'learn':\n",
        "            self.mix_layer = nn.Linear(hid_dim*(mix_k+1), mix_k+1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, t = data.x, data.edge_index, data.t\n",
        "        # 1) CT-GAT stack -> node embeddings\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, edge_index, t)\n",
        "        # 2) Causal-Inspector: compute importance scores using last layer's attention\n",
        "        # Use last layer's get_attention\n",
        "        importance = self.layers[-1].get_attention(data.x, data.edge_index)  # [N]\n",
        "        # normalize importance\n",
        "        imp_norm = (importance - importance.min()) / (importance.max() - importance.min() + 1e-9)\n",
        "        # select environment nodes: lowest re fraction\n",
        "        N = x.size(0)\n",
        "        k_env = max(1, int(self.env_ratio * N))\n",
        "        # get indices sorted by importance ascending\n",
        "        sorted_idx = torch.argsort(imp_norm)  # ascending\n",
        "        env_idx = sorted_idx[:k_env]\n",
        "        causal_idx = sorted_idx[k_env:]\n",
        "        # 3) Causal-Intervener: causal mixup on environment nodes (create augmented features x_aug)\n",
        "        x_aug = x.clone()\n",
        "        if len(causal_idx) == 0:\n",
        "            # no causal nodes -> skip\n",
        "            pass\n",
        "        else:\n",
        "            # for each env node, pick top-k causal nodes by importance (descending)\n",
        "            causal_sorted_desc = torch.argsort(imp_norm, descending=True)\n",
        "            topk = causal_sorted_desc[:self.mix_k]\n",
        "            # prepare mix vectors\n",
        "            for j in env_idx:\n",
        "                xj = x[j]\n",
        "                # gather causal features\n",
        "                causal_feats = x[topk]  # [k, dim]\n",
        "                if self.mix_mode == 'importance':\n",
        "                    # weights proportional to importance\n",
        "                    w_c = imp_norm[topk]\n",
        "                    w_c = w_c / (w_c.sum() + 1e-9)\n",
        "                    w_env = 1.0 - w_c.sum()\n",
        "                    mix = w_env * xj + (w_c.view(-1,1) * causal_feats).sum(dim=0)\n",
        "                else:\n",
        "                    # learnable weights: concatenate and pass through softmax\n",
        "                    vec = torch.cat([xj.unsqueeze(0), causal_feats], dim=0).view(1,-1)  # [1, (k+1)*dim]\n",
        "                    logits = self.mix_layer(vec)  # [1, k+1]\n",
        "                    alpha = F.softmax(logits, dim=1).view(-1)  # [k+1]\n",
        "                    mix = alpha[0]*xj + (alpha[1:].view(-1,1) * causal_feats).sum(dim=0)\n",
        "                x_aug[j] = mix\n",
        "        # 4) final prediction from augmented embeddings\n",
        "        logits = self.mlp(x_aug).view(-1)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs, imp_norm\n",
        "\n",
        "# ---------------------------\n",
        "# 損失・評価関数\n",
        "# ---------------------------\n",
        "def compute_metrics(y_true, y_prob, threshold=0.5):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true))>1 else 0.5\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    ap = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else 0.0\n",
        "    return {'auc': auc, 'f1': f1, 'ap': ap}\n",
        "\n",
        "# ---------------------------\n",
        "# 学習ループ（簡易）\n",
        "# ---------------------------\n",
        "def train_model(model, data, epochs=50, lr=3e-3, weight_decay=1e-5):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCELoss()\n",
        "    best_auc = 0.0\n",
        "    best_state = None\n",
        "    y = data.y.cpu().numpy()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        probs, imp = model(data)\n",
        "        loss = criterion(probs, data.y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # eval\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            probs_eval, _ = model(data)\n",
        "            metrics = compute_metrics(y, probs_eval.cpu().numpy())\n",
        "        if metrics['auc'] > best_auc:\n",
        "            best_auc = metrics['auc']\n",
        "            best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
        "        if epoch % 10 == 0 or epoch==1:\n",
        "            print(f\"Epoch {epoch:03d} loss={loss.item():.4f} auc={metrics['auc']:.4f} f1={metrics['f1']:.4f} ap={metrics['ap']:.4f}\")\n",
        "    # load best\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k: v.to(device) for k,v in best_state.items()})\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# 実行\n",
        "# ---------------------------\n",
        "model = CaT_GNN(in_dim=data.x.size(1), hid_dim=128, heads=4, n_layers=2, env_ratio=0.2, mix_k=3, mix_mode='learn')\n",
        "model = train_model(model, data, epochs=60, lr=3e-3)\n",
        "# 最終評価\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    probs, imp = model(data)\n",
        "    metrics = compute_metrics(data.y.cpu().numpy(), probs.cpu().numpy())\n",
        "print(\"Final metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "lNov30S8pAa3",
        "outputId": "9aefe4ae-b1ae-40c7-bc6f-0515615c0ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-595145810.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Colab / Python セルに貼って実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGATConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 全体像\n",
        "\n",
        "ログ\n",
        "\n",
        " ↓ 時間窓集約\n",
        "\n",
        "ユーザ × リソース グラフ（t=1）\n",
        "\n",
        " ↓ GCN\n",
        "\n",
        "ノード埋め込み h_i^t\n",
        "\n",
        " ↓ Pooling\n",
        "\n",
        "グラフ埋め込み g_t\n",
        "\n",
        " ↓\n",
        "\n",
        "graph_embeddings = [g_1, g_2, ..., g_T]\n",
        "\n",
        " ↓\n",
        "\n",
        "HMM\n",
        "\n"
      ],
      "metadata": {
        "id": "3vk3zFhhw-I9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データ前処理、特徴量処理"
      ],
      "metadata": {
        "id": "JYDAKPTasFSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"aryan208/cybersecurity-threat-detection-logs\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3GVTIH1sLnq",
        "outputId": "44c77e19-5a1c-453e-f981-4f8eafabea24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/aryan208/cybersecurity-threat-detection-logs?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 95.7M/95.7M [00:02<00:00, 49.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/aryan208/cybersecurity-threat-detection-logs/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#前処理\n",
        "!pip install pandas numpy torch torch-geometric scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tzMMRE3sjK8",
        "outputId": "38259848-5814-46b8-8af2-65cb8fee8dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/root/.cache/kagglehub/datasets/aryan208/cybersecurity-threat-detection-logs/versions/1\"\n",
        "\n",
        "for root, dirs, files in os.walk(base_path):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-vkBEGuspdc",
        "outputId": "2e808db4-3bfe-4677-b3a8-7c4d69220ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/aryan208/cybersecurity-threat-detection-logs/versions/1/cybersecurity_threat_detection_logs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(os.path.join(base_path, \"/root/.cache/kagglehub/datasets/aryan208/cybersecurity-threat-detection-logs/versions/1/cybersecurity_threat_detection_logs.csv\"))\n",
        "\n",
        "df.head()\n",
        "df.info()\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkxROCbqtE6y",
        "outputId": "82540be5-e43b-481f-bd67-23a40cf1f935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000000 entries, 0 to 5999999\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Dtype \n",
            "---  ------             ----- \n",
            " 0   timestamp          object\n",
            " 1   source_ip          object\n",
            " 2   dest_ip            object\n",
            " 3   protocol           object\n",
            " 4   action             object\n",
            " 5   threat_label       object\n",
            " 6   log_type           object\n",
            " 7   bytes_transferred  int64 \n",
            " 8   user_agent         object\n",
            " 9   request_path       object\n",
            "dtypes: int64(1), object(9)\n",
            "memory usage: 457.8+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['timestamp', 'source_ip', 'dest_ip', 'protocol', 'action',\n",
              "       'threat_label', 'log_type', 'bytes_transferred', 'user_agent',\n",
              "       'request_path'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={\n",
        "    \"time\": \"timestamp\",   # 必要に応じて\n",
        "})\n",
        "\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df = df.sort_values(\"timestamp\")"
      ],
      "metadata": {
        "id": "3aMvsfirtbAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#時間窓でログを集約（HMM の観測単位）\n",
        "WINDOW = \"1h\"\n",
        "\n",
        "df['time_window'] = df['timestamp'].dt.floor(WINDOW)\n",
        "\n",
        "agg = (\n",
        "    df.groupby(['time_window', 'source_ip', 'dest_ip'])\n",
        "      .agg(\n",
        "          bytes_sum=('bytes_transferred', 'sum'),\n",
        "          access_count=('bytes_transferred', 'count')\n",
        "      )\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "agg.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ABOTmjertgK8",
        "outputId": "0602f993-47a8-40a9-a707-d5a4383471f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  time_window       source_ip        dest_ip  bytes_sum  access_count\n",
              "0  2024-01-01  103.172.167.96    192.168.1.1      25015             1\n",
              "1  2024-01-01  103.172.167.96  192.168.1.102      38357             1\n",
              "2  2024-01-01  103.172.167.96  192.168.1.103      10858             1\n",
              "3  2024-01-01  103.172.167.96  192.168.1.119      28199             1\n",
              "4  2024-01-01  103.172.167.96  192.168.1.128       6035             1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0035ba6-be30-4069-b89c-3c932d841882\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_window</th>\n",
              "      <th>source_ip</th>\n",
              "      <th>dest_ip</th>\n",
              "      <th>bytes_sum</th>\n",
              "      <th>access_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-01-01</td>\n",
              "      <td>103.172.167.96</td>\n",
              "      <td>192.168.1.1</td>\n",
              "      <td>25015</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-01-01</td>\n",
              "      <td>103.172.167.96</td>\n",
              "      <td>192.168.1.102</td>\n",
              "      <td>38357</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-01-01</td>\n",
              "      <td>103.172.167.96</td>\n",
              "      <td>192.168.1.103</td>\n",
              "      <td>10858</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-01-01</td>\n",
              "      <td>103.172.167.96</td>\n",
              "      <td>192.168.1.119</td>\n",
              "      <td>28199</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-01-01</td>\n",
              "      <td>103.172.167.96</td>\n",
              "      <td>192.168.1.128</td>\n",
              "      <td>6035</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0035ba6-be30-4069-b89c-3c932d841882')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0035ba6-be30-4069-b89c-3c932d841882 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0035ba6-be30-4069-b89c-3c932d841882');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "agg"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ユーザ × リソースをノードとして符号化\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_user = LabelEncoder()\n",
        "le_res = LabelEncoder()\n",
        "\n",
        "agg['user_id'] = le_user.fit_transform(agg['source_ip'])\n",
        "agg['res_id']  = le_res.fit_transform(agg['dest_ip'])"
      ],
      "metadata": {
        "id": "UUpngvAntlKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PyTorch Geometric 用グラフ構造に変換\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "graphs = []\n",
        "times = []\n",
        "\n",
        "for t, g in agg.groupby(\"time_window\"):\n",
        "    nodes = pd.unique(g[['source_ip', 'dest_ip']].values.ravel())\n",
        "    node_map = {n: i for i, n in enumerate(nodes)}\n",
        "\n",
        "    edge_index = torch.tensor(\n",
        "        [[node_map[u], node_map[v]] for u, v in zip(g['source_ip'], g['dest_ip'])],\n",
        "        dtype=torch.long\n",
        "    ).t().contiguous()\n",
        "\n",
        "    edge_attr = torch.tensor(\n",
        "        g[['bytes_sum', 'access_count']].values,\n",
        "        dtype=torch.float\n",
        "    )\n",
        "\n",
        "    data_t = Data(\n",
        "        edge_index=edge_index,\n",
        "        edge_attr=edge_attr,\n",
        "        num_nodes=len(nodes)\n",
        "    )\n",
        "\n",
        "    graphs.append(data_t)\n",
        "    times.append(t)\n",
        "\n",
        "# すでに groupby が時系列ならOK\n",
        "assert len(graphs) == len(times)"
      ],
      "metadata": {
        "id": "BMHwS5LnygLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #PyTorch Geometric 用グラフ構造に変換\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "# edge_index = torch.from_numpy(\n",
        "#     np.vstack([\n",
        "#         agg['user_id'].values,\n",
        "#         agg['res_id'].values\n",
        "#     ])\n",
        "# ).long()\n",
        "\n",
        "\n",
        "# edge_attr = torch.from_numpy(\n",
        "#     agg[['bytes_sum', 'access_count']].values\n",
        "# ).float()\n",
        "\n",
        "# data = Data(\n",
        "#     edge_index=edge_index,\n",
        "#     edge_attr=edge_attr,\n",
        "#     num_nodes=max(agg['user_id'].max(), agg['res_id'].max()) + 1\n",
        "# )\n",
        "\n",
        "# data\n",
        "\n",
        "# #時間窓ごとにグラフを分割（HMM入力用）\n",
        "# graphs = {}\n",
        "\n",
        "# for t, g in agg.groupby(\"time_window\"):\n",
        "#     edge_index = torch.from_numpy(\n",
        "#         np.vstack([g['user_id'].values, g['res_id'].values])\n",
        "#     ).long()\n",
        "\n",
        "#     edge_attr = torch.from_numpy(\n",
        "#         g[['bytes_sum', 'access_count']].values\n",
        "#     ).float()\n",
        "\n",
        "#     graphs[t] = Data(\n",
        "#         edge_index=edge_index,\n",
        "#         edge_attr=edge_attr,\n",
        "#         num_nodes=data.num_nodes\n",
        "#     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SysbzQVQtx8I",
        "outputId": "9a7c4cb4-c93d-4731-d916-00c7cd5238b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 5482788], edge_attr=[5482788, 2], num_nodes=354)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN によるノード埋め込み（PyTorch Geometric）"
      ],
      "metadata": {
        "id": "1LtXe0kRvKyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(num_nodes, hidden_dim)\n",
        "        self.conv1 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = self.embedding.weight\n",
        "        x = self.conv1(x, data.edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, data.edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Ux3HKL8xvJrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# グラフ全体埋め込み（Graph-level Representation）"
      ],
      "metadata": {
        "id": "mM8kKZhLvU6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#②-1 Mean Pooling（最も安定\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "def graph_embedding(node_emb):\n",
        "    return node_emb.mean(dim=0)\n"
      ],
      "metadata": {
        "id": "3JowBYrXvSfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#②-2 Attention Pooling（発展）\n",
        "from torch_geometric.nn import AttentionalAggregation\n",
        "import torch\n",
        "\n",
        "model = GCNEncoder(num_nodes=data.num_nodes, hidden_dim=64)\n",
        "node_emb = model(data)\n",
        "\n",
        "att_pool = AttentionalAggregation(\n",
        "    gate_nn=torch.nn.Linear(64, 1)\n",
        ")\n",
        "\n",
        "batch = torch.zeros(node_emb.size(0), dtype=torch.long)\n",
        "g_t = att_pool(node_emb, batch)\n",
        "\n",
        "print(g_t.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-nZyLi-vZ75",
        "outputId": "8e3bed34-3cb2-401d-bf62-dfe615e5f835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# graph_embeddings"
      ],
      "metadata": {
        "id": "zbZIZOh0xZIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_embeddings = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data_t in graphs:   # 時間窓ごとのグラフ\n",
        "        node_emb = model(data_t)  # (N_t, d)\n",
        "\n",
        "        batch = torch.zeros(\n",
        "            node_emb.size(0),\n",
        "            dtype=torch.long,\n",
        "            device=node_emb.device\n",
        "        )\n",
        "\n",
        "        g_t = att_pool(node_emb, batch)  # (1, d)\n",
        "        graph_embeddings.append(g_t.squeeze(0).cpu().numpy())\n",
        "\n",
        "print(len(graph_embeddings), graph_embeddings[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A6oQWqsxaTv",
        "outputId": "fad6a95b-5dc2-4ef5-ab69-baeeda2687fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "365 (64,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN 出力 → HMM（hmmlearn）"
      ],
      "metadata": {
        "id": "9kT6tJbLvkwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmluyCS0wZob",
        "outputId": "36535492-4759-4d02-8408-939ab8d81c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
            "Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from hmmlearn.hmm import GaussianHMM\n",
        "\n",
        "X = np.stack(graph_embeddings)  # (T, d)\n",
        "\n",
        "hmm = GaussianHMM(\n",
        "    n_components=3,\n",
        "    covariance_type=\"full\",\n",
        "    n_iter=200,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "hmm.fit(X)\n",
        "states = hmm.predict(X)"
      ],
      "metadata": {
        "id": "jiwcUrXAvnYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEIEt6fRzBFn",
        "outputId": "c07832c8-5799-4e38-afa2-88ad77abd718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 2 0 1 0 1 0 1 2 2 2 2 2 2 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 2 2 2 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
            " 1 0 1 0 1 2 2 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 2 2\n",
            " 0 1 2 0 1 0 1 0 1 0 1 0 1 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
            " 2 2 2 2 2 2 2 0 1 2 2 0 1 0 1 0 1 0 1 0 1 0 1 2 0 1 2 2 1 0 1 0 1 0 1 0 1\n",
            " 0 1 0 1 0 1 2 2 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 2 2 2 0 1 0 1 2 2 2\n",
            " 2 2 1 0 1 0 1 2 2 0 1 0 1 0 1 0 1 2 2 2 1 0 1 0 1 0 1 0 1 2 2 1 0 1 0 1 0\n",
            " 1 1 0 1 2 1 2 0 1 2 2 2 1 0 1 0 1 2 0 1 2 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
            " 2 2 2 2 1 0 1 0 1 0 1 2 1 2 0 1 0 1 0 0 1 2 2 2 0 1 0 1 0 2 0 1 0 1 0 1 2\n",
            " 2 2 2 2 0 1 0 1 0 1 2 2 2 0 1 2 0 1 0 1 0 1 0 1 0 1 0 1 0 1 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#②-1 状態ごとの「滞在時間」\n",
        "import pandas as pd\n",
        "\n",
        "state_series = pd.Series(states)\n",
        "\n",
        "print(state_series.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiMNjOY0zDCg",
        "outputId": "256d2042-a9be-4703-e320-ad2a85d6af13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    152\n",
            "0    140\n",
            "2     73\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#②-2 状態遷移行列（最重要）\n",
        "print(hmm.transmat_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmmaOX58zp4d",
        "outputId": "4be3be38-dfd7-45af-9cdb-3e9ae3580840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00714289 0.98571425 0.00714286]\n",
            " [0.78947368 0.0131579  0.19736842]\n",
            " [0.26388883 0.15277784 0.58333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#②-3 状態ごとのグラフ特徴量（意味付け）\n",
        "import numpy as np\n",
        "\n",
        "for k in range(3):\n",
        "    idx = np.where(states == k)[0]\n",
        "    print(f\"State {k}: mean ||g_t|| =\",\n",
        "          np.mean(np.linalg.norm(X[idx], axis=1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoU-WBW7zvje",
        "outputId": "2c278b07-83dc-4208-f9f9-0a7dea4cb9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State 0: mean ||g_t|| = 6.299156\n",
            "State 1: mean ||g_t|| = 6.2389765\n",
            "State 2: mean ||g_t|| = 6.2719097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#④-1 異常状態（例：state=2）の時間窓を抽出\n",
        "anomaly_times = [times[t] for t in np.where(states == 2)[0]]\n",
        "print(anomaly_times)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9CJLr-qzyy-",
        "outputId": "da24cdba-e7da-4d89-f9c3-0770c07af08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Timestamp('2024-01-04 00:00:00'), Timestamp('2024-01-11 00:00:00'), Timestamp('2024-01-12 00:00:00'), Timestamp('2024-01-13 00:00:00'), Timestamp('2024-01-14 00:00:00'), Timestamp('2024-01-15 00:00:00'), Timestamp('2024-01-16 00:00:00'), Timestamp('2024-02-27 00:00:00'), Timestamp('2024-02-28 00:00:00'), Timestamp('2024-02-29 00:00:00'), Timestamp('2024-03-20 00:00:00'), Timestamp('2024-03-21 00:00:00'), Timestamp('2024-04-19 00:00:00'), Timestamp('2024-04-20 00:00:00'), Timestamp('2024-04-23 00:00:00'), Timestamp('2024-05-06 00:00:00'), Timestamp('2024-05-28 00:00:00'), Timestamp('2024-05-29 00:00:00'), Timestamp('2024-05-30 00:00:00'), Timestamp('2024-05-31 00:00:00'), Timestamp('2024-06-01 00:00:00'), Timestamp('2024-06-02 00:00:00'), Timestamp('2024-06-03 00:00:00'), Timestamp('2024-06-06 00:00:00'), Timestamp('2024-06-07 00:00:00'), Timestamp('2024-06-20 00:00:00'), Timestamp('2024-06-23 00:00:00'), Timestamp('2024-06-24 00:00:00'), Timestamp('2024-07-10 00:00:00'), Timestamp('2024-07-11 00:00:00'), Timestamp('2024-07-31 00:00:00'), Timestamp('2024-08-01 00:00:00'), Timestamp('2024-08-02 00:00:00'), Timestamp('2024-08-07 00:00:00'), Timestamp('2024-08-08 00:00:00'), Timestamp('2024-08-09 00:00:00'), Timestamp('2024-08-10 00:00:00'), Timestamp('2024-08-11 00:00:00'), Timestamp('2024-08-17 00:00:00'), Timestamp('2024-08-18 00:00:00'), Timestamp('2024-08-27 00:00:00'), Timestamp('2024-08-28 00:00:00'), Timestamp('2024-08-29 00:00:00'), Timestamp('2024-09-08 00:00:00'), Timestamp('2024-09-09 00:00:00'), Timestamp('2024-09-20 00:00:00'), Timestamp('2024-09-22 00:00:00'), Timestamp('2024-09-25 00:00:00'), Timestamp('2024-09-26 00:00:00'), Timestamp('2024-09-27 00:00:00'), Timestamp('2024-10-03 00:00:00'), Timestamp('2024-10-06 00:00:00'), Timestamp('2024-10-23 00:00:00'), Timestamp('2024-10-24 00:00:00'), Timestamp('2024-10-25 00:00:00'), Timestamp('2024-10-26 00:00:00'), Timestamp('2024-11-03 00:00:00'), Timestamp('2024-11-05 00:00:00'), Timestamp('2024-11-13 00:00:00'), Timestamp('2024-11-14 00:00:00'), Timestamp('2024-11-15 00:00:00'), Timestamp('2024-11-21 00:00:00'), Timestamp('2024-11-28 00:00:00'), Timestamp('2024-11-29 00:00:00'), Timestamp('2024-11-30 00:00:00'), Timestamp('2024-12-01 00:00:00'), Timestamp('2024-12-02 00:00:00'), Timestamp('2024-12-09 00:00:00'), Timestamp('2024-12-10 00:00:00'), Timestamp('2024-12-11 00:00:00'), Timestamp('2024-12-14 00:00:00'), Timestamp('2024-12-29 00:00:00'), Timestamp('2024-12-30 00:00:00')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ベンチマーク"
      ],
      "metadata": {
        "id": "C0l7hTWx0ZBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# time_window ごとに不正が1回でもあれば1\n",
        "y_true = (\n",
        "    df.groupby(\"time_window\")[\"threat_label\"]\n",
        "      .max()\n",
        "      .loc[times]\n",
        "      .values\n",
        ")\n"
      ],
      "metadata": {
        "id": "J_mnjk6Zz-DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4jzMpSJ728Q",
        "outputId": "5d4e5217-ab21-4057-bc77-32c053e94b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious'\n",
            " 'suspicious' 'suspicious' 'suspicious' 'suspicious' 'suspicious']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HMM-only"
      ],
      "metadata": {
        "id": "xQbsFXXT5CEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HMM-only\n",
        "# 各時間窓の統計量\n",
        "features = []\n",
        "\n",
        "for t in times:\n",
        "    g = agg[agg['time_window'] == t]\n",
        "\n",
        "    features.append([\n",
        "        g['bytes_sum'].sum(),\n",
        "        g['access_count'].sum(),\n",
        "        g['source_ip'].nunique(),\n",
        "        g['dest_ip'].nunique()\n",
        "    ])\n",
        "\n",
        "X_hmm = np.array(features)  # (T, d)"
      ],
      "metadata": {
        "id": "neJzDY504zge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hmmlearn.hmm import GaussianHMM\n",
        "\n",
        "hmm_only = GaussianHMM(\n",
        "    n_components=3,\n",
        "    covariance_type=\"full\",\n",
        "    n_iter=200,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "hmm_only.fit(X_hmm)\n",
        "\n",
        "states_hmm = hmm_only.predict(X_hmm)\n",
        "loglik_hmm = hmm_only.score_samples(X_hmm)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjIPE_PE4-wr",
        "outputId": "0a173853-54f0-4b4c-8543-fd3dd8d4ba91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.base:Model is not converging.  Current: -3489.311706447532 is not greater than -3251.0525685331772. Delta is -238.2591379143546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN-only（時間なし・構造のみ）"
      ],
      "metadata": {
        "id": "N7qibkq65EtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(num_nodes, hidden_dim)\n",
        "        self.conv1 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = self.embedding.weight\n",
        "        x = self.conv1(x, data.edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, data.edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fltqSsgW5EGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#グラフ埋め込み（mean pooling）\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "model = GCNEncoder(num_nodes=data.num_nodes, hidden_dim=64)\n",
        "\n",
        "graph_embeddings = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for d in graphs:   # ← Timestampは使わない\n",
        "        node_emb = model(d)\n",
        "        batch = torch.zeros(node_emb.size(0), dtype=torch.long)\n",
        "        g_emb = global_mean_pool(node_emb, batch)\n",
        "        graph_embeddings.append(g_emb.squeeze(0))\n",
        "\n",
        "\n",
        "# list → Tensor\n",
        "graph_embeddings = torch.stack(graph_embeddings)  # (T, d)\n",
        "\n",
        "# Tensor → numpy（HMM 用）\n",
        "X_gnn = graph_embeddings.numpy()\n"
      ],
      "metadata": {
        "id": "i-oFwDHx5L6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#異常スコア（距離ベース）\n",
        "center = X_gnn.mean(axis=0)\n",
        "score_gnn = np.linalg.norm(X_gnn - center, axis=1)\n",
        "\n",
        "print(center)\n",
        "print(score_gnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DugaKcw75Q2m",
        "outputId": "42aa0cbc-bbc6-46dc-8c11-22fd8b7d22fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.0626632  -0.45314085  1.1826874  -0.29683053 -0.7799158  -0.40817636\n",
            "  1.400655    0.56546646  0.7829114  -0.38766617 -0.22717665 -1.350349\n",
            "  0.14194407 -1.8211545   0.15707104 -0.02916639  0.41207504 -0.00380835\n",
            " -1.8934249  -0.01651706  0.99174637  1.6753844   0.82970005 -0.05753732\n",
            " -1.2248442   1.9541584  -0.57943296  0.55176485 -0.08248364  0.6468075\n",
            " -1.9211559   0.00267815 -1.6548649   1.2441369   1.3403865   0.26201084\n",
            "  0.827159   -0.96655476 -0.17738171  1.0208024  -0.22396646  0.8368466\n",
            " -1.3960623   0.39841127 -1.2554045  -1.0415889   0.71536136 -0.2646621\n",
            " -1.2645024   0.9809791  -1.9708035   0.07174475 -0.35369718 -0.4743427\n",
            "  0.13070817 -1.2983385   1.5321132   1.3450783  -2.6692235   0.904907\n",
            " -1.9256772  -0.1683672   1.7575938  -0.15285511]\n",
            "[0.6390015  0.5170152  0.47815874 0.64287055 0.6356545  0.46365407\n",
            " 0.5752285  0.55194    0.70990396 0.68600875 0.6230674  0.50173646\n",
            " 0.64828026 0.6158026  0.6435692  0.6641283  0.4418879  0.5409468\n",
            " 0.48976758 0.5045158  0.625446   0.5751386  0.7778826  0.51966226\n",
            " 0.6362787  0.6584994  0.60349154 0.5978094  0.64131254 0.58407027\n",
            " 0.47751346 0.6175214  0.4982214  0.5369943  0.5295684  0.5751961\n",
            " 0.47089788 0.5656302  0.6488293  0.57493436 0.52145636 0.42359498\n",
            " 0.52166146 0.62927324 0.633568   0.5315892  0.7114861  0.56079406\n",
            " 0.783318   0.5929224  0.5263169  0.6794315  0.59343386 0.49888632\n",
            " 0.6893554  0.65139526 0.53486514 0.6884252  0.630626   0.51874167\n",
            " 0.63432497 0.52787584 0.59670854 0.59279716 0.5789861  0.6518102\n",
            " 0.49653527 0.62745    0.5106734  0.62038296 0.87408745 0.4631469\n",
            " 0.61932987 0.5870071  0.5839099  0.6409957  0.59859234 0.53847647\n",
            " 0.62464905 0.6213566  0.6063982  0.51498544 0.62950057 0.6809204\n",
            " 0.47476122 0.43353483 0.54912746 0.6353853  0.5459859  0.61027604\n",
            " 0.5416903  0.5061784  0.5874091  0.3782745  0.6051307  0.5284236\n",
            " 0.5554794  0.49650273 0.6037831  0.5120213  0.49697095 0.5937417\n",
            " 0.51510644 0.5589356  0.42141068 0.67016745 0.5850069  0.56995213\n",
            " 0.46239212 0.48707312 0.5123116  0.6177649  0.4612994  0.5323624\n",
            " 0.49330977 0.6284024  0.423016   0.6750297  0.6696403  0.6081989\n",
            " 0.49254    0.68600786 0.49950868 0.5279571  0.57639986 0.5903771\n",
            " 0.4941127  0.58540094 0.51231223 0.47314158 0.5630708  0.5425367\n",
            " 0.6216679  0.6920456  0.50804806 0.4961343  0.57049024 0.49475566\n",
            " 0.49206936 0.5316692  0.51226354 0.629986   0.6094774  0.5824203\n",
            " 0.6018261  0.71270806 0.51144636 0.5966008  0.51887745 0.67241013\n",
            " 0.60476685 0.5661267  0.4862058  0.561466   0.46901575 0.7363202\n",
            " 0.6599098  0.5295582  0.6306864  0.5545919  0.52667844 0.5856697\n",
            " 0.40912867 0.5180048  0.5544318  0.50462663 0.5974362  0.6764783\n",
            " 0.4870575  0.53627306 0.55608135 0.5554446  0.60334176 0.5726272\n",
            " 0.58870393 0.60334885 0.62935364 0.5046978  0.43502596 0.65511566\n",
            " 0.4704995  0.59551597 0.64257413 0.7157585  0.6192439  0.5770677\n",
            " 0.5149885  0.59682345 0.53779054 0.5870411  0.42611364 0.597073\n",
            " 0.5705311  0.7830391  0.5373316  0.59182715 0.4531773  0.52922094\n",
            " 0.6562266  0.60519063 0.616286   0.49054137 0.61275584 0.4908655\n",
            " 0.6370955  0.5798863  0.51178306 0.4725451  0.5470872  0.67231107\n",
            " 0.49855027 0.6415342  0.5681241  0.56066346 0.521393   0.55298495\n",
            " 0.6959629  0.57710826 0.62973714 0.8311618  0.6214503  0.5876832\n",
            " 0.5206723  0.5278503  0.6742431  0.6122706  0.5770272  0.4476816\n",
            " 0.46509588 0.4991297  0.43602657 0.5228867  0.47082645 0.5775897\n",
            " 0.5758671  0.5669231  0.50225633 0.57576513 0.7342582  0.6560788\n",
            " 0.49919364 0.47516558 0.4847629  0.62390506 0.59313715 0.62035483\n",
            " 0.49103653 0.4410187  0.53858465 0.57168925 0.5119403  0.67631644\n",
            " 0.55603474 0.6331056  0.68025476 0.5555799  0.80584687 0.53713244\n",
            " 0.63008595 0.57673174 0.6277852  0.42911395 0.71865946 0.46244815\n",
            " 0.502289   0.5854452  0.5285357  0.673435   0.56700474 0.5800281\n",
            " 0.6557203  0.49659723 0.58851606 0.59359974 0.46839887 0.5296128\n",
            " 0.47690246 0.49542344 0.57889575 0.55330336 0.53405607 0.624873\n",
            " 0.5714451  0.5874086  0.45614332 0.6897898  0.61849314 0.55917454\n",
            " 0.65041065 0.4690464  0.56144416 0.57415235 0.58965385 0.44118237\n",
            " 0.5939679  0.88882744 0.64868814 0.5755166  0.4060988  0.63752043\n",
            " 0.5450725  0.677902   0.5241756  0.48904485 0.6996776  0.6583039\n",
            " 0.6775498  0.59828776 0.53154707 0.46333858 0.659448   0.57824785\n",
            " 0.5396636  0.4647622  0.46772644 0.5496306  0.71583873 0.5298729\n",
            " 0.60087365 0.62693185 0.5296873  0.6566388  0.5794785  0.5245888\n",
            " 0.5506507  0.45363522 0.55164444 0.52794385 0.54332596 0.7736797\n",
            " 0.5570617  0.4297416  0.65927    0.44263673 0.4982242  0.63232315\n",
            " 0.51521236 0.57861686 0.52556205 0.66359955 0.55831933 0.5875151\n",
            " 0.78241485 0.44344053 0.4954056  0.6079124  0.5919284  0.6613098\n",
            " 0.5386181  0.59479254 0.5187725  0.6498589  0.5747768  0.59243155\n",
            " 0.70433384 0.5791714  0.5590134  0.52001745 0.6967823  0.5887115\n",
            " 0.5197107  0.5434097  0.6843882  0.56570363 0.53722245]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM（時系列のみ・構造なし）"
      ],
      "metadata": {
        "id": "Aw2mccUa5Xvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X_lstm = torch.tensor(X_hmm, dtype=torch.float32)  # (T, d)\n",
        "X_lstm = X_lstm.unsqueeze(0)  # (1, T, d)\n",
        "\n",
        "class LSTMAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.decoder = nn.LSTM(hidden_dim, input_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z, _ = self.encoder(x)\n",
        "        out, _ = self.decoder(z)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "9fb9vrqH5YdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = LSTMAE(input_dim=X_hmm.shape[1])\n",
        "opt = torch.optim.Adam(model_lstm.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "for epoch in range(100):\n",
        "    opt.zero_grad()\n",
        "    recon = model_lstm(X_lstm)\n",
        "    loss = loss_fn(recon, X_lstm)\n",
        "    loss.backward()\n",
        "    opt.step()\n"
      ],
      "metadata": {
        "id": "3j_KK4DV5dkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    recon = model_lstm(X_lstm)\n",
        "    score_lstm = torch.mean((recon - X_lstm) ** 2, dim=2).squeeze().numpy()\n",
        "\n",
        "print(score_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOWtSjeR5f-n",
        "outputId": "d6ffea85-9b94-4cd2-bab2-8ffad1a9ba19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.2881220e+16 4.2275934e+16 4.1085365e+16 4.1986028e+16 4.2687366e+16\n",
            " 4.3764372e+16 4.2926377e+16 4.1566036e+16 4.1744101e+16 4.1364164e+16\n",
            " 4.2540968e+16 4.2185628e+16 4.1679810e+16 4.2279894e+16 4.1667045e+16\n",
            " 4.2299690e+16 4.1719208e+16 4.2235158e+16 4.1705103e+16 4.1334538e+16\n",
            " 4.1628468e+16 4.2270261e+16 4.1451606e+16 4.3263519e+16 4.1877426e+16\n",
            " 4.2262899e+16 4.2443524e+16 4.3745221e+16 4.2203534e+16 4.3581553e+16\n",
            " 4.1897543e+16 4.1744844e+16 4.2635874e+16 4.2853066e+16 4.1549977e+16\n",
            " 4.3372173e+16 4.1805232e+16 4.2541887e+16 4.2240544e+16 4.2999052e+16\n",
            " 4.1924408e+16 4.2434960e+16 4.2680512e+16 4.2041171e+16 4.1097924e+16\n",
            " 4.1419256e+16 4.2250126e+16 4.2636621e+16 4.2023519e+16 4.1747645e+16\n",
            " 4.1665525e+16 4.3515423e+16 4.1688640e+16 4.2339311e+16 4.2458638e+16\n",
            " 4.1155094e+16 4.3044252e+16 4.3214247e+16 4.1935687e+16 4.1731543e+16\n",
            " 4.2213911e+16 4.0757195e+16 4.2137782e+16 4.2596833e+16 4.1740700e+16\n",
            " 4.1590827e+16 4.1855960e+16 4.3797353e+16 4.4014885e+16 4.1782421e+16\n",
            " 4.2752933e+16 4.2830990e+16 4.3210889e+16 4.1281314e+16 4.2963267e+16\n",
            " 4.1969115e+16 4.1587185e+16 4.3028949e+16 4.2767850e+16 4.1717829e+16\n",
            " 4.3420397e+16 4.1651880e+16 4.2541651e+16 4.2891790e+16 4.1497626e+16\n",
            " 4.1159861e+16 4.3155191e+16 4.2924539e+16 4.3234292e+16 4.2312218e+16\n",
            " 4.3181425e+16 4.2598821e+16 4.2248391e+16 4.1790972e+16 4.1727952e+16\n",
            " 4.2937252e+16 4.1355480e+16 4.2278309e+16 4.2661335e+16 4.1352808e+16\n",
            " 4.2903846e+16 4.2673335e+16 4.2018481e+16 4.3133575e+16 4.1814406e+16\n",
            " 4.2437992e+16 4.2313051e+16 4.1724559e+16 4.2808330e+16 4.3264906e+16\n",
            " 4.1359311e+16 4.1672135e+16 4.2229433e+16 4.2260365e+16 4.2324811e+16\n",
            " 4.2338297e+16 4.2651632e+16 4.2642682e+16 4.1652120e+16 4.2582028e+16\n",
            " 4.1850247e+16 4.2503052e+16 4.3325938e+16 4.3555628e+16 4.3633762e+16\n",
            " 4.1616279e+16 4.2167435e+16 4.3385492e+16 4.3294881e+16 4.3150630e+16\n",
            " 4.1289402e+16 4.1178209e+16 4.3447954e+16 4.2645130e+16 4.1048050e+16\n",
            " 4.1761350e+16 4.2645654e+16 4.3039262e+16 4.2592950e+16 4.1770636e+16\n",
            " 4.1690517e+16 4.2563993e+16 4.2702893e+16 4.3632680e+16 4.3699248e+16\n",
            " 4.3350587e+16 4.2284215e+16 4.1819938e+16 4.2661146e+16 4.2917229e+16\n",
            " 4.2081437e+16 4.1372587e+16 4.4100213e+16 4.3688236e+16 4.2930466e+16\n",
            " 4.3816002e+16 4.1397463e+16 4.2101537e+16 4.3203836e+16 4.2799633e+16\n",
            " 4.1733428e+16 4.1436822e+16 4.2804293e+16 4.2651250e+16 4.3674608e+16\n",
            " 4.3475420e+16 4.2633018e+16 4.1870837e+16 4.4026589e+16 4.3365190e+16\n",
            " 4.0647631e+16 4.2273821e+16 4.1864124e+16 4.2389751e+16 4.2182441e+16\n",
            " 4.1393954e+16 4.3457360e+16 4.2002594e+16 4.2026410e+16 4.1353496e+16\n",
            " 4.0970664e+16 4.2346977e+16 4.1910630e+16 4.1542874e+16 4.3606661e+16\n",
            " 4.1822940e+16 4.2172649e+16 4.1645523e+16 4.2592796e+16 4.3598978e+16\n",
            " 4.2259360e+16 4.3347292e+16 4.1109048e+16 4.2679322e+16 4.2988237e+16\n",
            " 4.2717100e+16 4.3300615e+16 4.1620784e+16 4.3546850e+16 4.3231440e+16\n",
            " 4.2196928e+16 4.1923360e+16 4.2155486e+16 4.3358180e+16 4.1910119e+16\n",
            " 4.1459543e+16 4.2675654e+16 4.2767287e+16 4.3359619e+16 4.2123351e+16\n",
            " 4.3018882e+16 4.1615055e+16 4.2993052e+16 4.2955540e+16 4.3703620e+16\n",
            " 4.2437923e+16 4.2082060e+16 4.1603866e+16 4.1692446e+16 4.2661184e+16\n",
            " 4.3105653e+16 4.2305196e+16 4.1704098e+16 4.1760762e+16 4.2390163e+16\n",
            " 4.1826127e+16 4.2406196e+16 4.2946327e+16 4.2254301e+16 4.1017217e+16\n",
            " 4.3377611e+16 4.2512540e+16 4.2158969e+16 4.3737391e+16 4.3638380e+16\n",
            " 4.2603799e+16 4.1656772e+16 4.3831812e+16 4.2074457e+16 4.2156156e+16\n",
            " 4.3309883e+16 4.1942280e+16 4.2426112e+16 4.3037114e+16 4.2117055e+16\n",
            " 4.2125495e+16 4.2559651e+16 4.2554965e+16 4.2956601e+16 4.2287475e+16\n",
            " 4.2713600e+16 4.2864383e+16 4.2441076e+16 4.2468954e+16 4.2181935e+16\n",
            " 4.2367675e+16 4.3036345e+16 4.1767805e+16 4.2264136e+16 4.2177395e+16\n",
            " 4.1348745e+16 4.3521432e+16 4.1568235e+16 4.1692798e+16 4.0843692e+16\n",
            " 4.2973729e+16 4.1341989e+16 4.1558585e+16 4.1839428e+16 4.2071090e+16\n",
            " 4.2755772e+16 4.1715093e+16 4.2898859e+16 4.2122033e+16 4.3036844e+16\n",
            " 4.1826298e+16 4.1871671e+16 4.2835732e+16 4.2807531e+16 4.0958122e+16\n",
            " 4.2415401e+16 4.2965633e+16 4.2894891e+16 4.2775783e+16 4.1409287e+16\n",
            " 4.2818646e+16 4.3078677e+16 4.2195232e+16 4.1532424e+16 4.3149526e+16\n",
            " 4.2534805e+16 4.2550950e+16 4.2741401e+16 4.2792735e+16 4.2651272e+16\n",
            " 4.2345242e+16 4.2069376e+16 4.2626623e+16 4.3128236e+16 4.1301801e+16\n",
            " 4.3101887e+16 4.3848507e+16 4.2301056e+16 4.2698739e+16 4.2069660e+16\n",
            " 4.2801673e+16 4.3195405e+16 4.2489394e+16 4.2734645e+16 4.0813068e+16\n",
            " 4.2578416e+16 4.1898828e+16 4.2402889e+16 4.1358259e+16 4.1723395e+16\n",
            " 4.3188142e+16 4.2545658e+16 4.2532211e+16 4.2767549e+16 4.1463477e+16\n",
            " 4.3638199e+16 4.1968582e+16 4.1798587e+16 4.2127913e+16 4.2123261e+16\n",
            " 4.1761191e+16 4.2789325e+16 4.2084224e+16 4.1892952e+16 4.2478416e+16\n",
            " 4.1367763e+16 4.1774905e+16 4.1264512e+16 4.0550882e+16 4.2265571e+16\n",
            " 4.3164043e+16 4.2982212e+16 4.2984089e+16 4.2472691e+16 4.2039990e+16\n",
            " 4.1568553e+16 4.4449742e+16 4.1850698e+16 4.2126577e+16 4.4118961e+16\n",
            " 4.2387887e+16 4.2667180e+16 4.1890371e+16 4.1354810e+16 4.2192019e+16\n",
            " 4.3303187e+16 4.1349381e+16 4.1741898e+16 4.3993552e+16 4.0022494e+16\n",
            " 4.2139466e+16 4.3241198e+16 4.1867681e+16 4.3063004e+16 4.2993357e+16\n",
            " 4.2296735e+16 4.1635460e+16 4.4084390e+16 4.4026164e+16 4.3196853e+16]\n"
          ]
        }
      ]
    }
  ]
}